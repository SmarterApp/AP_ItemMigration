package org.opentestsystem.ap.migration.migration;

import org.apache.commons.collections4.CollectionUtils;
import org.apache.commons.io.FileUtils;
import org.apache.commons.lang.StringUtils;
import org.opentestsystem.ap.common.datastore.DataStoreAttachmentManager;
import org.opentestsystem.ap.common.datastore.DataStoreDataManager;
import org.opentestsystem.ap.common.datastore.DataStoreItemManager;
import org.opentestsystem.ap.common.datastore.DataStoreUtility;
import org.opentestsystem.ap.common.datastore.entity.ItemEntity;
import org.opentestsystem.ap.common.exception.SystemException;
import org.opentestsystem.ap.common.model.Item;
import org.opentestsystem.ap.common.model.ItemFactory;
import org.opentestsystem.ap.common.saaif.mapper.IatModelMapper;
import org.opentestsystem.ap.common.saaif.mapper.IatModelMapperFactory;
import org.opentestsystem.ap.common.saaif.mapper.model.ImportItem;
import org.opentestsystem.ap.common.saaif.mapper.model.SkipMigration;
import org.opentestsystem.ap.common.saaif.mapper.util.MigrationFileUtil;
import org.opentestsystem.ap.migration.ApplicationProperties;
import org.opentestsystem.ap.migration.gitlab.GitLabSyncManager;
import org.opentestsystem.ap.migration.model.BranchEditedException;
import org.opentestsystem.ap.migration.model.FailedMigrationException;
import org.opentestsystem.ap.migration.model.ItemMerge;
import org.opentestsystem.ap.migration.model.MigrationContext;
import org.opentestsystem.ap.migration.util.ApplicationDependencyProvider;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.List;
import java.util.Set;
import java.util.stream.Collectors;

import static java.lang.String.format;
import static org.opentestsystem.ap.common.model.ModelConstants.BranchNames.BRANCH_MASTER;

public abstract class AbstractImportMigration extends AbstractMigration {
    private final static Logger log = LoggerFactory.getLogger(AbstractMigration.class);

    protected final static boolean YES_SYNC_ATTACHMENTS = true;
    protected final static boolean DO_NOT_SYNC_ATTACHMENTS = false;

    private final String migrationName;
    private final Set<String> migrationItemType;
    private final MigrationFileUtil migrationFileUtil;
    protected final GitLabSyncManager itemBankSyncManager;
    private final ItemFactory itemFactory;

    public AbstractImportMigration(final ApplicationProperties applicationProperties,
                                   final DataStoreDataManager dataManager,
                                   final DataStoreUtility dataStoreUtility,
                                   final DataStoreAttachmentManager dataStoreAttachmentManager,
                                   final DataStoreItemManager dataStoreItemManager,
                                   final ApplicationDependencyProvider applicationDependencyProvider) {
        this(applicationProperties, dataManager, dataStoreUtility, dataStoreAttachmentManager,
                applicationDependencyProvider, dataStoreItemManager, StringUtils.EMPTY);
    }

    public AbstractImportMigration(final ApplicationProperties applicationProperties,
                                   final DataStoreDataManager dataManager,
                                   final DataStoreUtility dataStoreUtility,
                                   final DataStoreAttachmentManager dataStoreAttachmentManager,
                                   final ApplicationDependencyProvider applicationDependencyProvider,
                                   final DataStoreItemManager dataStoreItemManager,
                                   final String... migrationItemType) {
        super(applicationDependencyProvider, applicationProperties, dataManager, dataStoreItemManager, dataStoreUtility,
                dataStoreAttachmentManager);
        this.migrationName = getClass().getSimpleName();
        this.migrationItemType = Arrays.stream(migrationItemType).filter(s -> !s.isEmpty()).collect(Collectors.toSet());
        this.migrationFileUtil = applicationDependencyProvider.getMigrationFileUtil();
        this.itemBankSyncManager = applicationDependencyProvider.getItemBankSyncManager();
        this.itemFactory = new ItemFactory();
    }

    public MigrationFileUtil getMigrationFileUtil() {
        return migrationFileUtil;
    }

    @Override
    protected ItemEntity migrateEntity(final ItemEntity itemEntity, MigrationContext migrationContext) {
        if (!migrationContext.getMigrationDefinition().isRequiresImportFiles()) {
            throw new SystemException(migrationContext.getMigrationDefinition().getMigrationName() + " is missing the requiresImportFiles and will always result in skipping migration.  Check configuration");
        }

        if(!itemEntity.getItemJson().isImported()) {
            throw new SkipMigration("item %s is not imported", migrationContext.getMigrationDefinition().getMigrationName(), itemEntity.getItemId());
        }

        this.checkSkipMigration(itemEntity);

        List<String> sectionsEditedBlockingMigration = collectEditedBranchesBlockingMigration(itemEntity);

        if (CollectionUtils.isNotEmpty(sectionsEditedBlockingMigration)) {
            throw new BranchEditedException(String.join(", ", sectionsEditedBlockingMigration));
        }

        Path itemSyncDir;
        try {
            itemSyncDir = Files.createTempDirectory(itemEntity.getItemId());
        } catch (IOException e) {
            throw new SystemException(e.getMessage(), e);
        }

        ItemMerge itemMerge = null;

        try {
            ImportItem importItem = migrationContext.getImportItem().get();
            this.checkSkipMigration(importItem);

            IatModelMapper mapper = IatModelMapperFactory.getInstance().newModelMapper(
                    itemEntity.getItemJson().getType());

            Item newItem = itemFactory.newItem(itemEntity.getItemJson().getId(), itemEntity.getItemJson().getType());
            newItem.setItsId(itemEntity.getItemJson().getItsId());

            Item mappedItem = mapper.mapSaaifToIATModel(importItem.getItemProps(),
                    newItem,
                    importItem.getItemRelease(),
                    importItem.getSmarterAppMetadata(),
                    importItem.getWordlistreleaseType().orElse(null),
                    importItem.getWordlistPathString(),
                    itemSyncDir,
                    importItem.getItemImportSourcePath().toString());

            itemMerge = mergeItem(itemEntity.getItemJson(), mappedItem, itemSyncDir);

            itemMerge = mergeItemFromImportData(itemMerge, importItem, itemSyncDir);

            itemEntity.setItemJson(itemMerge.getMergedItem());
// TODO - Migration needs to be modified to follow the standard pattern code wise prior to being able to save attachments
//            Do not enable attchment syncing without team design discussion
//            syncAttachmentsToDataStore(itemEntity, itemMerge);
        } finally {
            cleanFiles(itemMerge, itemSyncDir);
        }

        return itemEntity;
    }

    private void cleanFiles(ItemMerge itemMerge, Path itemSyncDir) {
        try {
            if (itemMerge != null) {
                FileUtils.deleteDirectory(itemMerge.getAttachmentSyncDir().toFile());
            }
            if (itemSyncDir != null) {
                FileUtils.deleteDirectory(itemSyncDir.toFile());
            }
        } catch (IOException e) {
            log.error("Could not delete import file", e);
        }
    }

    List<String> collectEditedBranchesBlockingMigration(final ItemEntity itemEntity) {
        Collection<String> blockingSections = getEditedSectionsBlockingMigration();
        if (CollectionUtils.isNotEmpty(blockingSections)) {
            List<String> sectionsEdited = dataManager.findSectionsEdited(itemEntity.getItemId());
            return sectionsEdited
                    .stream()
                    .filter(sectionEdited -> blockingSections.stream().anyMatch(sectionEdited::equalsIgnoreCase))
                    .collect(Collectors.toList());
        }
        return Collections.emptyList();
    }

    /**
     * Returns true if text is found in item file
     *
     * @param importItem Loaded import item
     * @param textToFind Text to find
     * @return
     */
    boolean findTextInItemFile(ImportItem importItem, String textToFind) {
        Path itemFilePath = importItem.getItemFile().toPath();
        boolean found;
        try {
            String fileAsString = new String(Files.readAllBytes(itemFilePath));

            found = org.apache.commons.lang3.StringUtils.containsIgnoreCase(fileAsString, textToFind);

        } catch (IOException e) {
            throw new FailedMigrationException("Unexpected error reading SAAIF xml file " + e.getMessage(), e);
        }

        return found;
    }

    /**
     * Merge the mapped item from using data from the initial import files
     *
     * This method should be overwritten when updates need to be made using the raw initial import data (ItemRelease)
     *
     * @param itemMerge    the {@link ItemMerge} containing the results of the mapped item merge
     * @param importItem   the {@link ImportItem} containing the item loaded from import files
     * @param itemSyncDir  the {@link Path} to the imported attachments referenced by the mapped item
     * @return an {@link ItemMerge} containing the results of the merge
     */
    protected ItemMerge mergeItemFromImportData(ItemMerge itemMerge, ImportItem importItem, Path itemSyncDir) {
        return itemMerge;
    }

    /**
     * Merge the mapped item from the item import with the item entity.
     *
     * @param dataStoreItem the {@link Item} stored within TIMS
     * @param mappedItem    the mapped {@link Item} from the import model mappers
     * @param itemSyncDir   the {@link Path} to the imported attachments referenced by the mapped item
     * @return an {@link ItemMerge} containing the results of the merge
     */
    protected abstract ItemMerge mergeItem(Item dataStoreItem, Item mappedItem, Path itemSyncDir);

    /**
     * @return the sections that if edited will block the import migration
     */
    protected abstract Collection<String> getEditedSectionsBlockingMigration();

    /**
     * Throws {@link SkipMigration} if the migration should be skipped for the given entity.
     *
     * @param itemEntity The entity to check if the migration should be skipped.
     */
    protected void checkSkipMigration(ItemEntity itemEntity) {
        if (!migrationItemType.isEmpty() && !migrationItemType.contains(itemEntity.getItemJson().getType())) {
            throw new SkipMigration(format("item is not of type %s", migrationItemType));
        }
    }

    /**
     * Throws {@link SkipMigration} if the migration should be skipped for the given import item.  Import item has the
     * original import data taken from the import.zip so things like the saaif xml, the metadata xml, etc.  A migration
     * can use this data to check if the migration should be skipped.
     *
     * @param importItem The entity to check if the migration should be skipped.
     */
    protected void checkSkipMigration(ImportItem importItem) {
        // default to not skip
    }

    /**
     * Import based migrations should only migrate the master branch.  Extending classes should
     * not override this method.  This safe guards in the event the configuration for these migrations
     * has set "migrateBranches: true"
     *
     * @param migratedEntity The entity holding the branch name.
     * @return
     */
    protected boolean shouldMigrateBranch(ItemEntity migratedEntity) {
        return BRANCH_MASTER.equalsIgnoreCase(migratedEntity.getBranchName());
    }

    /**
     * Technically we need to sync more than just the 'master' folder in S3.  If a user is editing braille for example
     * they may have uploaded a file(s).  Those files are uploaded to the 'braille' folder in S3.  If migration only
     * syncs to the 'master' when the user commits their braille changes it could overwrite the files on 'master'. It is
     * an edge case because it is unlikely anyone is editing imported items, and it is unlikely the migration and the
     * user are using the same file name.
     * <p>
     * One thought is check in S3 if the folder for the branch exists.  If not then there is no need to sync to the
     * branch folder in S3.  Or we check if the file exists in the branch folder and only sync if it does.
     * <p>
     * Concrete migrations can overwrite this as they see fit.
     *
     * @param itemEntity the {@link ItemEntity} being migrated
     */
    private void syncAttachmentsToDataStore(ItemEntity itemEntity, ItemMerge itemMerge) {
        if (!itemMerge.isSyncAttachments() || !BRANCH_MASTER.equalsIgnoreCase(itemEntity.getBranchName())) {
            return;
        }

        // if we sync branches then we cannot sync everything in the itemSyncDir
        // braille should only sync braille files to the 'braille' folder in S3
        // asl should only sync asl files to the 'asl' folder in S3
        log.info("Import migration {} syncing attachments", migrationName);
        itemBankSyncManager
                .syncAttachmentsToDataStore(itemEntity.getItemId(), BRANCH_MASTER, itemMerge.getAttachmentSyncDir());
    }

    public String getMigrationName() {
        return migrationName;
    }
}
